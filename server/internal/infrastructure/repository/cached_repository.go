package repository

import (
	"context"
	"fmt"
	"time"

	"gorm.io/gorm"

	fieldEntity "github.com/easyspace-ai/luckdb/server/internal/domain/fields/entity"
	fieldRepo "github.com/easyspace-ai/luckdb/server/internal/domain/fields/repository"
	fieldValueobject "github.com/easyspace-ai/luckdb/server/internal/domain/fields/valueobject"
	recordEntity "github.com/easyspace-ai/luckdb/server/internal/domain/record/entity"
	recordRepo "github.com/easyspace-ai/luckdb/server/internal/domain/record/repository"
	recordValueobject "github.com/easyspace-ai/luckdb/server/internal/domain/record/valueobject"
	"github.com/easyspace-ai/luckdb/server/pkg/database"
	"github.com/easyspace-ai/luckdb/server/pkg/logger"
)

// CachedFieldRepository å¸¦ç¼“å­˜çš„å­—æ®µä»“å‚¨åŒ…è£…å™¨
// âœ… ä¼˜åŒ–ï¼šå®ç°æŸ¥è¯¢ç¼“å­˜ï¼Œå‡å°‘æ•°æ®åº“æŸ¥è¯¢
type CachedFieldRepository struct {
	repo         fieldRepo.FieldRepository
	cacheService CacheProvider
	ttl          time.Duration
}

// NewCachedFieldRepository åˆ›å»ºå¸¦ç¼“å­˜çš„å­—æ®µä»“å‚¨
func NewCachedFieldRepository(
	repo fieldRepo.FieldRepository,
	cacheService CacheProvider,
	ttl time.Duration,
) fieldRepo.FieldRepository {
	if ttl == 0 {
		ttl = 5 * time.Minute // é»˜è®¤5åˆ†é’Ÿ
	}

	return &CachedFieldRepository{
		repo:         repo,
		cacheService: cacheService,
		ttl:          ttl,
	}
}

// buildCacheKey æ„å»ºç¼“å­˜é”®
func (r *CachedFieldRepository) buildCacheKey(prefix, id string) string {
	return fmt.Sprintf("field:%s:%s", prefix, id)
}

// FindByID æ ¹æ®IDæŸ¥æ‰¾å­—æ®µï¼ˆå¸¦ç¼“å­˜ï¼‰
func (r *CachedFieldRepository) FindByID(ctx context.Context, id fieldValueobject.FieldID) (*fieldEntity.Field, error) {
	cacheKey := r.buildCacheKey("id", id.String())

	// å°è¯•ä»ç¼“å­˜è·å–
	var field *fieldEntity.Field
	if err := r.cacheService.Get(ctx, cacheKey, &field); err == nil {
		logger.Debug("field cache hit",
			logger.String("field_id", id.String()))
		return field, nil
	}

	// ç¼“å­˜æœªå‘½ä¸­ï¼ŒæŸ¥è¯¢æ•°æ®åº“
	field, err := r.repo.FindByID(ctx, id)
	if err != nil {
		return nil, err
	}

	// å†™å…¥ç¼“å­˜
	if field != nil {
		if err := r.cacheService.Set(ctx, cacheKey, field, r.ttl); err != nil {
			logger.Warn("failed to cache field",
				logger.String("field_id", id.String()),
				logger.ErrorField(err))
		}
	}

	return field, nil
}

// FindByTableID æŸ¥æ‰¾è¡¨çš„æ‰€æœ‰å­—æ®µï¼ˆå¸¦ç¼“å­˜ï¼‰
func (r *CachedFieldRepository) FindByTableID(ctx context.Context, tableID string) ([]*fieldEntity.Field, error) {
	// âœ… å…³é”®ä¿®å¤ï¼šåœ¨äº‹åŠ¡ä¸­ç¦ç”¨ç¼“å­˜ï¼Œç›´æ¥æŸ¥è¯¢æ•°æ®åº“
	// åŸå› ï¼šäº‹åŠ¡ä¸­çš„æŸ¥è¯¢å¯èƒ½å—åˆ°éš”ç¦»çº§åˆ«å½±å“ï¼Œç¼“å­˜å¯èƒ½å¯¼è‡´æ•°æ®ä¸ä¸€è‡´
	if database.InTransaction(ctx) {
		logger.Info("ğŸ” CachedFieldRepository.FindByTableID åœ¨äº‹åŠ¡ä¸­ï¼Œç¦ç”¨ç¼“å­˜ï¼Œç›´æ¥æŸ¥è¯¢æ•°æ®åº“",
			logger.String("table_id", tableID))
		return r.repo.FindByTableID(ctx, tableID)
	}

	cacheKey := r.buildCacheKey("table", tableID)

	// âœ… æ·»åŠ è¯¦ç»†æ—¥å¿—ï¼šç¼“å­˜æŸ¥è¯¢
	logger.Info("ğŸ” CachedFieldRepository.FindByTableID å¼€å§‹æŸ¥è¯¢",
		logger.String("table_id", tableID),
		logger.String("cache_key", cacheKey))

	// å°è¯•ä»ç¼“å­˜è·å–
	var fields []*fieldEntity.Field
	if err := r.cacheService.Get(ctx, cacheKey, &fields); err == nil {
		logger.Info("ğŸ” CachedFieldRepository.FindByTableID ç¼“å­˜å‘½ä¸­",
			logger.String("table_id", tableID),
			logger.Int("cached_count", len(fields)))
		return fields, nil
	}

	logger.Info("ğŸ” CachedFieldRepository.FindByTableID ç¼“å­˜æœªå‘½ä¸­ï¼ŒæŸ¥è¯¢æ•°æ®åº“",
		logger.String("table_id", tableID))

	// ç¼“å­˜æœªå‘½ä¸­ï¼ŒæŸ¥è¯¢æ•°æ®åº“
	fields, err := r.repo.FindByTableID(ctx, tableID)
	if err != nil {
		return nil, err
	}

	logger.Info("ğŸ” CachedFieldRepository.FindByTableID æ•°æ®åº“æŸ¥è¯¢å®Œæˆ",
		logger.String("table_id", tableID),
		logger.Int("found_count", len(fields)))

	// å†™å…¥ç¼“å­˜
	if err := r.cacheService.Set(ctx, cacheKey, fields, r.ttl); err != nil {
		logger.Warn("failed to cache fields",
			logger.String("table_id", tableID),
			logger.ErrorField(err))
	}

	return fields, nil
}

// Save ä¿å­˜å­—æ®µï¼ˆæ›´æ–°åæ¸…é™¤ç¼“å­˜ï¼‰
func (r *CachedFieldRepository) Save(ctx context.Context, field *fieldEntity.Field) error {
	if err := r.repo.Save(ctx, field); err != nil {
		return err
	}

	// æ¸…é™¤ç›¸å…³ç¼“å­˜
	r.invalidateCache(ctx, field)
	return nil
}

// Delete åˆ é™¤å­—æ®µï¼ˆæ¸…é™¤ç¼“å­˜ï¼‰
func (r *CachedFieldRepository) Delete(ctx context.Context, id fieldValueobject.FieldID) error {
	// å…ˆè·å–å­—æ®µä¿¡æ¯ï¼ˆç”¨äºæ¸…é™¤ç¼“å­˜ï¼‰
	field, _ := r.repo.FindByID(ctx, id)

	if err := r.repo.Delete(ctx, id); err != nil {
		return err
	}

	// æ¸…é™¤ç¼“å­˜
	if field != nil {
		r.invalidateCache(ctx, field)
	}
	return nil
}

// invalidateCache ä½¿å­—æ®µç›¸å…³ç¼“å­˜å¤±æ•ˆ
func (r *CachedFieldRepository) invalidateCache(ctx context.Context, field *fieldEntity.Field) {
	keys := []string{
		r.buildCacheKey("id", field.ID().String()),
		r.buildCacheKey("table", field.TableID()),
	}

	if err := r.cacheService.Delete(ctx, keys...); err != nil {
		logger.Warn("failed to invalidate field cache",
			logger.String("field_id", field.ID().String()),
			logger.ErrorField(err))
	}

	// æ¸…é™¤è¡¨æ ¼å­—æ®µåˆ—è¡¨ç¼“å­˜
	pattern := fmt.Sprintf("field:table:%s", field.TableID())
	if err := r.cacheService.InvalidatePattern(ctx, pattern); err != nil {
		logger.Warn("failed to invalidate field pattern cache",
			logger.String("pattern", pattern),
			logger.ErrorField(err))
	}
}

// å®ç°å…¶ä»–æ¥å£æ–¹æ³•ï¼ˆç›´æ¥å§”æ‰˜ç»™åº•å±‚repoï¼‰
func (r *CachedFieldRepository) FindByName(ctx context.Context, tableID string, name fieldValueobject.FieldName) (*fieldEntity.Field, error) {
	return r.repo.FindByName(ctx, tableID, name)
}

func (r *CachedFieldRepository) Exists(ctx context.Context, id fieldValueobject.FieldID) (bool, error) {
	return r.repo.Exists(ctx, id)
}

func (r *CachedFieldRepository) ExistsByName(ctx context.Context, tableID string, name fieldValueobject.FieldName, excludeID *fieldValueobject.FieldID) (bool, error) {
	return r.repo.ExistsByName(ctx, tableID, name, excludeID)
}

func (r *CachedFieldRepository) List(ctx context.Context, filter fieldRepo.FieldFilter) ([]*fieldEntity.Field, int64, error) {
	return r.repo.List(ctx, filter)
}

func (r *CachedFieldRepository) BatchSave(ctx context.Context, fields []*fieldEntity.Field) error {
	if err := r.repo.BatchSave(ctx, fields); err != nil {
		return err
	}

	// æ¸…é™¤æ‰€æœ‰ç›¸å…³è¡¨æ ¼çš„ç¼“å­˜
	tableIDs := make(map[string]bool)
	for _, field := range fields {
		tableIDs[field.TableID()] = true
	}

	for tableID := range tableIDs {
		cacheKey := r.buildCacheKey("table", tableID)
		if err := r.cacheService.Delete(ctx, cacheKey); err != nil {
			logger.Warn("failed to invalidate cache after batch save",
				logger.String("table_id", tableID),
				logger.ErrorField(err))
		}
	}

	return nil
}

func (r *CachedFieldRepository) BatchDelete(ctx context.Context, ids []fieldValueobject.FieldID) error {
	return r.repo.BatchDelete(ctx, ids)
}

func (r *CachedFieldRepository) GetVirtualFields(ctx context.Context, tableID string) ([]*fieldEntity.Field, error) {
	return r.repo.GetVirtualFields(ctx, tableID)
}

func (r *CachedFieldRepository) GetComputedFields(ctx context.Context, tableID string) ([]*fieldEntity.Field, error) {
	return r.repo.GetComputedFields(ctx, tableID)
}

func (r *CachedFieldRepository) GetFieldsByType(ctx context.Context, tableID string, fieldType fieldValueobject.FieldType) ([]*fieldEntity.Field, error) {
	return r.repo.GetFieldsByType(ctx, tableID, fieldType)
}

func (r *CachedFieldRepository) UpdateOrder(ctx context.Context, fieldID fieldValueobject.FieldID, order float64) error {
	return r.repo.UpdateOrder(ctx, fieldID, order)
}

func (r *CachedFieldRepository) GetMaxOrder(ctx context.Context, tableID string) (float64, error) {
	return r.repo.GetMaxOrder(ctx, tableID)
}

func (r *CachedFieldRepository) NextID() fieldValueobject.FieldID {
	return r.repo.NextID()
}

// CachedRecordRepository å¸¦ç¼“å­˜çš„è®°å½•ä»“å‚¨åŒ…è£…å™¨
// âœ… ä¼˜åŒ–ï¼šå®ç°æŸ¥è¯¢ç¼“å­˜ï¼Œå‡å°‘æ•°æ®åº“æŸ¥è¯¢
type CachedRecordRepository struct {
	repo         recordRepo.RecordRepository
	cacheService CacheProvider
	ttl          time.Duration
}

// NewCachedRecordRepository åˆ›å»ºå¸¦ç¼“å­˜çš„è®°å½•ä»“å‚¨
func NewCachedRecordRepository(
	repo recordRepo.RecordRepository,
	cacheService CacheProvider,
	ttl time.Duration,
) recordRepo.RecordRepository {
	if ttl == 0 {
		ttl = 2 * time.Minute // è®°å½•ç¼“å­˜æ—¶é—´è¾ƒçŸ­ï¼Œé»˜è®¤2åˆ†é’Ÿ
	}

	return &CachedRecordRepository{
		repo:         repo,
		cacheService: cacheService,
		ttl:          ttl,
	}
}

// buildCacheKey æ„å»ºç¼“å­˜é”®
func (r *CachedRecordRepository) buildCacheKey(prefix, tableID, recordID string) string {
	return fmt.Sprintf("record:%s:%s:%s", prefix, tableID, recordID)
}

// FindByTableAndID æ ¹æ®è¡¨æ ¼IDå’Œè®°å½•IDæŸ¥æ‰¾è®°å½•ï¼ˆå¸¦ç¼“å­˜ï¼‰
func (r *CachedRecordRepository) FindByTableAndID(ctx context.Context, tableID string, id recordValueobject.RecordID) (*recordEntity.Record, error) {
	cacheKey := r.buildCacheKey("id", tableID, id.String())

	// å°è¯•ä»ç¼“å­˜è·å–
	var record *recordEntity.Record
	if err := r.cacheService.Get(ctx, cacheKey, &record); err == nil {
		logger.Debug("record cache hit",
			logger.String("table_id", tableID),
			logger.String("record_id", id.String()))
		return record, nil
	}

	// ç¼“å­˜æœªå‘½ä¸­ï¼ŒæŸ¥è¯¢æ•°æ®åº“
	record, err := r.repo.FindByTableAndID(ctx, tableID, id)
	if err != nil {
		return nil, err
	}

	// å†™å…¥ç¼“å­˜
	if record != nil {
		if err := r.cacheService.Set(ctx, cacheKey, record, r.ttl); err != nil {
			logger.Warn("failed to cache record",
				logger.String("record_id", id.String()),
				logger.ErrorField(err))
		}
	}

	return record, nil
}

// Save ä¿å­˜è®°å½•ï¼ˆæ›´æ–°åæ¸…é™¤ç¼“å­˜ï¼‰
func (r *CachedRecordRepository) Save(ctx context.Context, record *recordEntity.Record) error {
	if err := r.repo.Save(ctx, record); err != nil {
		return err
	}

	// æ¸…é™¤è®°å½•ç¼“å­˜
	cacheKey := r.buildCacheKey("id", record.TableID(), record.ID().String())
	if err := r.cacheService.Delete(ctx, cacheKey); err != nil {
		logger.Warn("failed to invalidate record cache",
			logger.String("record_id", record.ID().String()),
			logger.ErrorField(err))
	}

	// æ¸…é™¤è¡¨æ ¼è®°å½•åˆ—è¡¨ç¼“å­˜
	pattern := fmt.Sprintf("record:list:%s:*", record.TableID())
	if err := r.cacheService.InvalidatePattern(ctx, pattern); err != nil {
		logger.Warn("failed to invalidate record list cache",
			logger.String("pattern", pattern),
			logger.ErrorField(err))
	}

	return nil
}

// DeleteByTableAndID åˆ é™¤è®°å½•ï¼ˆæ¸…é™¤ç¼“å­˜ï¼‰
func (r *CachedRecordRepository) DeleteByTableAndID(ctx context.Context, tableID string, id recordValueobject.RecordID) error {
	if err := r.repo.DeleteByTableAndID(ctx, tableID, id); err != nil {
		return err
	}

	// æ¸…é™¤ç¼“å­˜
	cacheKey := r.buildCacheKey("id", tableID, id.String())
	if err := r.cacheService.Delete(ctx, cacheKey); err != nil {
		logger.Warn("failed to invalidate record cache after delete",
			logger.String("record_id", id.String()),
			logger.ErrorField(err))
	}

	// æ¸…é™¤è¡¨æ ¼è®°å½•åˆ—è¡¨ç¼“å­˜
	pattern := fmt.Sprintf("record:list:%s:*", tableID)
	if err := r.cacheService.InvalidatePattern(ctx, pattern); err != nil {
		logger.Warn("failed to invalidate record list cache",
			logger.String("pattern", pattern),
			logger.ErrorField(err))
	}

	return nil
}

// List åˆ—å‡ºè®°å½•ï¼ˆå¸¦ç¼“å­˜ï¼Œä½†ç¼“å­˜æ—¶é—´è¾ƒçŸ­ï¼‰
func (r *CachedRecordRepository) List(ctx context.Context, filter recordRepo.RecordFilter) ([]*recordEntity.Record, int64, error) {
	// è®°å½•åˆ—è¡¨ç¼“å­˜æ—¶é—´å¾ˆçŸ­ï¼Œå› ä¸ºæ•°æ®å˜åŒ–é¢‘ç¹
	// è¿™é‡Œä½¿ç”¨è¾ƒçŸ­çš„TTLï¼ˆ30ç§’ï¼‰
	shortTTL := 30 * time.Second
	if r.ttl < shortTTL {
		shortTTL = r.ttl
	}

	// æ„å»ºç¼“å­˜é”®ï¼ˆåŸºäºè¿‡æ»¤æ¡ä»¶ï¼‰
	cacheKey := fmt.Sprintf("record:list:%s:%d:%d", *filter.TableID, filter.Limit, filter.Offset)

	// å°è¯•ä»ç¼“å­˜è·å–
	var result struct {
		Records []*recordEntity.Record
		Total   int64
	}

	if err := r.cacheService.Get(ctx, cacheKey, &result); err == nil {
		logger.Debug("record list cache hit",
			logger.String("table_id", *filter.TableID))
		return result.Records, result.Total, nil
	}

	// ç¼“å­˜æœªå‘½ä¸­ï¼ŒæŸ¥è¯¢æ•°æ®åº“
	records, total, err := r.repo.List(ctx, filter)
	if err != nil {
		return nil, 0, err
	}

	// å†™å…¥ç¼“å­˜
	result.Records = records
	result.Total = total
	if err := r.cacheService.Set(ctx, cacheKey, result, shortTTL); err != nil {
		logger.Warn("failed to cache record list",
			logger.String("table_id", *filter.TableID),
			logger.ErrorField(err))
	}

	return records, total, nil
}

// å®ç°å…¶ä»–æ¥å£æ–¹æ³•ï¼ˆç›´æ¥å§”æ‰˜ç»™åº•å±‚repoï¼‰
func (r *CachedRecordRepository) FindByID(ctx context.Context, id recordValueobject.RecordID) (*recordEntity.Record, error) {
	return r.repo.FindByID(ctx, id)
}

func (r *CachedRecordRepository) BatchSave(ctx context.Context, records []*recordEntity.Record) error {
	if err := r.repo.BatchSave(ctx, records); err != nil {
		return err
	}

	// æ¸…é™¤æ‰€æœ‰ç›¸å…³è¡¨æ ¼çš„ç¼“å­˜
	tableIDs := make(map[string]bool)
	for _, record := range records {
		tableIDs[record.TableID()] = true
		cacheKey := r.buildCacheKey("id", record.TableID(), record.ID().String())
		if err := r.cacheService.Delete(ctx, cacheKey); err != nil {
			logger.Warn("failed to invalidate cache after batch save",
				logger.String("record_id", record.ID().String()),
				logger.ErrorField(err))
		}
	}

	for tableID := range tableIDs {
		pattern := fmt.Sprintf("record:list:%s:*", tableID)
		if err := r.cacheService.InvalidatePattern(ctx, pattern); err != nil {
			logger.Warn("failed to invalidate record list cache",
				logger.String("pattern", pattern),
				logger.ErrorField(err))
		}
	}

	return nil
}

func (r *CachedRecordRepository) BatchDelete(ctx context.Context, ids []recordValueobject.RecordID) error {
	// æ¥å£å®šä¹‰ä¸­æ²¡æœ‰tableIDï¼Œä½†å®é™…å®ç°éœ€è¦tableID
	// è¿™é‡Œéœ€è¦å…ˆæŸ¥è¯¢è®°å½•è·å–tableIDï¼Œæˆ–è€…ä½¿ç”¨å…¶ä»–æ–¹å¼
	// æš‚æ—¶ç›´æ¥å§”æ‰˜ç»™åº•å±‚repoï¼ˆå‡è®¾åº•å±‚repoä¼šå¤„ç†ï¼‰
	if err := r.repo.BatchDelete(ctx, ids); err != nil {
		return err
	}

	// æ¸…é™¤ç¼“å­˜ï¼ˆæ— æ³•çŸ¥é“tableIDï¼Œæ¸…é™¤æ‰€æœ‰ç›¸å…³ç¼“å­˜ï¼‰
	// æ³¨æ„ï¼šè¿™é‡Œæ¸…é™¤æ‰€æœ‰è®°å½•çš„ç¼“å­˜ï¼Œå¯èƒ½ä¼šæœ‰æ€§èƒ½å½±å“
	// åœ¨å®é™…åº”ç”¨ä¸­ï¼Œåº”è¯¥ä¼ å…¥tableIDæˆ–è€…è®°å½•ä¿¡æ¯
	for _, id := range ids {
		// å°è¯•ä»ç¼“å­˜ä¸­è·å–è®°å½•ä¿¡æ¯ä»¥è·å–tableID
		// å¦‚æœæ²¡æœ‰ç¼“å­˜ï¼Œåˆ™è·³è¿‡ï¼ˆç¼“å­˜å·²è‡ªåŠ¨å¤±æ•ˆï¼‰
		pattern := fmt.Sprintf("record:*:*:%s", id.String())
		if err := r.cacheService.InvalidatePattern(ctx, pattern); err != nil {
			logger.Warn("failed to invalidate record cache",
				logger.String("record_id", id.String()),
				logger.ErrorField(err))
		}
	}

	return nil
}

func (r *CachedRecordRepository) Exists(ctx context.Context, id recordValueobject.RecordID) (bool, error) {
	return r.repo.Exists(ctx, id)
}

func (r *CachedRecordRepository) FindByIDs(ctx context.Context, tableID string, ids []recordValueobject.RecordID) ([]*recordEntity.Record, error) {
	return r.repo.FindByIDs(ctx, tableID, ids)
}

func (r *CachedRecordRepository) FindByTableID(ctx context.Context, tableID string) ([]*recordEntity.Record, error) {
	return r.repo.FindByTableID(ctx, tableID)
}

func (r *CachedRecordRepository) Delete(ctx context.Context, id recordValueobject.RecordID) error {
	return r.repo.Delete(ctx, id)
}

func (r *CachedRecordRepository) CountByTableID(ctx context.Context, tableID string) (int64, error) {
	return r.repo.CountByTableID(ctx, tableID)
}

func (r *CachedRecordRepository) FindWithVersion(ctx context.Context, tableID string, id recordValueobject.RecordID, version recordValueobject.RecordVersion) (*recordEntity.Record, error) {
	return r.repo.FindWithVersion(ctx, tableID, id, version)
}

func (r *CachedRecordRepository) NextID() recordValueobject.RecordID {
	return r.repo.NextID()
}

// GetDB è·å–æ•°æ®åº“è¿æ¥ï¼ˆç”¨äºäº‹åŠ¡ç®¡ç†ï¼‰
// å¦‚æœåº•å±‚ä»“åº“å®ç°äº† GetDB æ–¹æ³•ï¼Œåˆ™è¿”å›å…¶æ•°æ®åº“è¿æ¥
func (r *CachedRecordRepository) GetDB() *gorm.DB {
	// å°è¯•ç±»å‹æ–­è¨€åˆ° RecordRepositoryDynamic
	if dynamicRepo, ok := r.repo.(*RecordRepositoryDynamic); ok {
		return dynamicRepo.GetDB()
	}
	// å¦‚æœåº•å±‚ä»“åº“ä¹Ÿæ˜¯ç¼“å­˜åŒ…è£…å™¨ï¼Œé€’å½’è°ƒç”¨
	if cachedRepo, ok := r.repo.(*CachedRecordRepository); ok {
		return cachedRepo.GetDB()
	}
	// å¦‚æœéƒ½ä¸åŒ¹é…ï¼Œè¿”å› nilï¼ˆè¿™ä¸åº”è¯¥å‘ç”Ÿï¼‰
	return nil
}

